{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZqLABekS5iLYIhaOqdo8Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jatingpt/NLP/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**What is NLP?**\n",
        "\n",
        "##**NLP is a technology which is used by machine to understand, analyse and manipulate human language.**\n",
        "\n",
        "##**It is a combination of Computer Science, Artificial Intelligence and Human Language.**"
      ],
      "metadata": {
        "id": "w5GtUdqK0W1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Applications of NLP- Alexa, Siri, Google Assistance, Google Translator, To checking the span messages etc.**"
      ],
      "metadata": {
        "id": "UMBgtlnl09Gt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Components of NLP->**\n",
        "                          1. NLU(Natural Language Understanding)\n",
        "                          2. NLG(Natural Language Generation)\n",
        "\n",
        "1. NLU- It is working on the probability of texts or searching that how many times that we have searched anything(e.g if we pressed \"G\" on google then it will automatically suggesting the \"Google\").\n",
        "\n",
        "2. NLG- It is basically generating something. E.g Google Translator."
      ],
      "metadata": {
        "id": "NO-GC-gx2Jzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**What are the challenges faced in NLP?**\n",
        "\n",
        "There are many challenges faced in NLP.\n",
        "\n",
        "1. Synonyms(Can't get the difference in Synos)\n",
        "2. Contextual Words(Difference in between \"Good\" and \"Better\".)\n",
        "3. Ambiguity(Hard to understand the emotion of the sentence.)\n",
        "4. Lack of research and developement.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xto_9HLh3Wm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Libraries that used in NLP- ScikitLearn, NLTK, Spacy, Tensorflow etc.**"
      ],
      "metadata": {
        "id": "j0FDRP9K9lPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The first major concern is from where we can get the data.\n",
        "\n",
        "###So we can get the data from the company itself, The data from the APIs, Web Scrapping and we can also do the survey to get the data."
      ],
      "metadata": {
        "id": "iisbcC2_3IFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the steps to create a Pipeline or the procedure to create a NLP Model.\n",
        "\n",
        "1.  DATA COLLECTION(From Google, Web, Company's Data.)\n",
        "\n",
        "2.  Data Cleaning(Removing Stop Words, Punctuation Etc.)\n",
        "\n",
        "3.  Data Preprocessing(Tokenization, Removing Digits, Creating Phrase)\n",
        "\n",
        "4.  Feature Engineering\n",
        "(Converting our data into binary numbers and removing the unimportant features.)\n",
        "\n",
        "5.  Build Model/Modeling(We can build the models by using different libraries)\n",
        "\n",
        "6.  Evaluation(Testing the models by Cross Validation, Random Cross Validation)\n",
        "\n",
        "7.  Deployment(On different website, cloud, AWS, Azure.)\n",
        "\n",
        "8.  Monetering and Updating(We can update and monitor our models in AWS or on Clouds)"
      ],
      "metadata": {
        "id": "e5KJp3_H3fuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Tokenization**"
      ],
      "metadata": {
        "id": "JWjH57vU562a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**What is PUNKT**- It is a module called PUNKT available in the NLTK. NLTK (Natural Language Toolkit) is used in Python to implement programs under the domain of Natural Language Processing. It contains a variety of libraries for various purposes like text classification, parsing, stemming, tokenizing, etc.\n",
        "\n",
        "\n",
        "##In NLTK, PUNKT is an unsupervised trainable model, which means it can be trained on unlabeled data (Data that has not been tagged with information identifying its characteristics, properties, or categories is referred to as unlabeled data.)"
      ],
      "metadata": {
        "id": "84GHfPri7e3m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "e32m7SRCuqNI",
        "outputId": "96d6d173-125a-49c5-b812-af773e12b64c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'king',\n",
              " 'of',\n",
              " 'Mathura',\n",
              " ',',\n",
              " 'a',\n",
              " 'kingdom',\n",
              " 'established',\n",
              " 'by',\n",
              " 'the',\n",
              " 'Vrishni',\n",
              " 'tribes',\n",
              " '.',\n",
              " 'Ugrasena',\n",
              " \"'s\",\n",
              " 'son',\n",
              " 'was',\n",
              " 'Kamsa',\n",
              " ',',\n",
              " 'who',\n",
              " 'imprisoned',\n",
              " 'Ugrasena',\n",
              " 'and',\n",
              " 'took',\n",
              " 'over',\n",
              " 'the',\n",
              " 'kingdom']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "x = \"The king of Mathura, a kingdom established by the Vrishni tribes. Ugrasena's son was Kamsa, who imprisoned Ugrasena and took over the kingdom\"\n",
        "w = word_tokenize(x)\n",
        "w\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Parts of Speech.**"
      ],
      "metadata": {
        "id": "7XY4Xg0s8J4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag\n",
        "p = pos_tag(w)    #In this section by this library we can giving some scodes to the words. E.g The=DT, King=NN, of=IN like this which is\n",
        "p"
      ],
      "metadata": {
        "id": "05d4wa516i46",
        "outputId": "f271a13b-55e5-4bf6-ca54-2ecddd581f3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DT'),\n",
              " ('king', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('Mathura', 'NNP'),\n",
              " (',', ','),\n",
              " ('a', 'DT'),\n",
              " ('kingdom', 'NN'),\n",
              " ('established', 'VBN'),\n",
              " ('by', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('Vrishni', 'NNP'),\n",
              " ('tribes', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Ugrasena', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('son', 'NN'),\n",
              " ('was', 'VBD'),\n",
              " ('Kamsa', 'NNP'),\n",
              " (',', ','),\n",
              " ('who', 'WP'),\n",
              " ('imprisoned', 'VBD'),\n",
              " ('Ugrasena', 'NNP'),\n",
              " ('and', 'CC'),\n",
              " ('took', 'VBD'),\n",
              " ('over', 'RP'),\n",
              " ('the', 'DT'),\n",
              " ('kingdom', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "var_new = word_tokenize(var)\n",
        "var_new"
      ],
      "metadata": {
        "id": "pdFTuwbC__wn",
        "outputId": "34dd9fe8-3815-4e8a-cfec-bcc4071a2bff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'king',\n",
              " 'of',\n",
              " 'Mathura',\n",
              " ',',\n",
              " 'a',\n",
              " 'kingdom',\n",
              " 'established',\n",
              " 'by',\n",
              " 'the',\n",
              " 'Vrishni',\n",
              " 'tribes',\n",
              " '.',\n",
              " 'Ugrasena',\n",
              " \"'s\",\n",
              " 'son',\n",
              " 'was',\n",
              " 'Kamsa',\n",
              " ',',\n",
              " 'who',\n",
              " 'imprisoned',\n",
              " 'Ugrasena',\n",
              " 'and',\n",
              " 'took',\n",
              " 'over',\n",
              " 'the',\n",
              " 'kingdom']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**How to remove the Stop Words?**\n"
      ],
      "metadata": {
        "id": "1mjoTIHV81Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "var = \"The king of Mathura, a kingdom established by the Vrishni tribes. Ugrasena's son was Kamsa, who imprisoned Ugrasena and took over the kingdom\"\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "var_new = word_tokenize(var)\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from string import punctuation\n",
        "\n",
        "stop = stopwords.words(\"english\")\n",
        "\n",
        "stop_word_list = list(punctuation) + stop  #By this we got the list of punctuation and all the stop words in english.\n",
        "stop_word_list"
      ],
      "metadata": {
        "id": "QzmaIz4l8XDt",
        "outputId": "9062373e-4ff4-43ea-df7a-04a2b9ff4381",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~',\n",
              " 'i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "520y7S5H9h3c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}